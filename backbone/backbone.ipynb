{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# th architecture to use\n",
    "arch = 'resnet50'\n",
    "# resnet50\n",
    "# resnet18\n",
    "# alexnet\n",
    "\n",
    "# load the pre-trained weights\n",
    "model_file = '%s_places365.pth.tar' % arch\n",
    "if not os.access(model_file, os.W_OK):\n",
    "    weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n",
    "    os.system('wget ' + weight_url)\n",
    "\n",
    "model = models.__dict__[arch](num_classes=365)\n",
    "checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
    "state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# load the image transformer\n",
    "centre_crop = trn.Compose([\n",
    "        trn.Resize((256,256)),\n",
    "        trn.CenterCrop(224),\n",
    "        trn.ToTensor(),\n",
    "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# load the class label\n",
    "file_name = 'categories_places365.txt'\n",
    "if not os.access(file_name, os.W_OK):\n",
    "    synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "    os.system('wget ' + synset_url)\n",
    "classes = list()\n",
    "with open(file_name) as class_file:\n",
    "    for line in class_file:\n",
    "        classes.append(line.strip().split(' ')[0][3:])\n",
    "classes = tuple(classes)\n",
    "\n",
    "# load the test image\n",
    "img_name = '12.jpg'\n",
    "if not os.access(img_name, os.W_OK):\n",
    "    img_url = 'http://places.csail.mit.edu/demo/' + img_name\n",
    "    os.system('wget ' + img_url)\n",
    "\n",
    "img = Image.open(img_name)\n",
    "input_img = V(centre_crop(img).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 prediction on 12.jpg\n",
      "0.685 -> patio\n",
      "0.240 -> restaurant_patio\n",
      "0.019 -> beer_garden\n",
      "0.010 -> courtyard\n",
      "0.010 -> porch\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "logit = model.forward(input_img)\n",
    "h_x = F.softmax(logit, 1).data.squeeze()\n",
    "probs, idx = h_x.sort(0, True)\n",
    "\n",
    "print('{} prediction on {}'.format(arch,img_name))\n",
    "# output the prediction\n",
    "for i in range(0, 5):\n",
    "    print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet_places365.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 2683/36500 [00:34<07:08, 78.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-bc2d6a704f69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total {} samples'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-207-bc2d6a704f69>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(arch)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentre_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;31m#         print(logit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mh_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/places365/lib/python3.7/site-packages/torchvision/models/alexnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/places365/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/places365/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/places365/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/places365/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/places365/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "backbone_network = 'alexnet'\n",
    "val_path = '../../places365_data/val_large/'\n",
    "val_data = os.listdir(val_path)\n",
    "val_data.sort()\n",
    "# model = VGG16_Places365(weights='places')\n",
    "\n",
    "# def save_prob_idx (prob,idx):\n",
    "#     sample = {}\n",
    "#     for i in range(int(prob.size()[0])):\n",
    "#         sample[int(idx[i])]= float(prob[i])\n",
    "#     return sample\n",
    "\n",
    "def validation(arch):\n",
    "    arch = 'alexnet'\n",
    "# resnet50, resnet18, alexnet\n",
    "    model_file = '%s_places365.pth.tar' % arch\n",
    "    print(model_file)\n",
    "    \n",
    "    if not os.access(model_file, os.W_OK):\n",
    "        weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n",
    "        os.system('wget ' + weight_url)\n",
    "\n",
    "    model = models.__dict__[arch](num_classes=365)\n",
    "    model.cuda()\n",
    "    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
    "    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    \n",
    "    centre_crop = trn.Compose([\n",
    "            trn.Resize((256,256)),\n",
    "            trn.CenterCrop(224),\n",
    "            trn.ToTensor(),\n",
    "            trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # load categories\n",
    "    file_name = 'categories_places365.txt'\n",
    "    if not os.access(file_name, os.W_OK):\n",
    "        synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "        os.system('wget ' + synset_url)\n",
    "    classes = list()\n",
    "    with open(file_name) as class_file:\n",
    "        for line in class_file:\n",
    "            classes.append(line.strip().split(' ')[0][3:])\n",
    "    classes = tuple(classes)\n",
    "\n",
    "    # start to val\n",
    "    val_res = []\n",
    "    count = 0\n",
    "    for data in tqdm(val_data):\n",
    "        image = Image.open(os.path.join(val_path,data)).convert('RGB') \n",
    "        input_img = V(centre_crop(image).unsqueeze(0)).cuda()\n",
    "        # forward pass\n",
    "        logit = model.forward(input_img)\n",
    "#         print(logit)\n",
    "        h_x = F.softmax(logit, 1).data.squeeze()\n",
    "#         print(h_x)\n",
    "#         probs, idx = h_x.sort(0, True)\n",
    "        name = data[10:-4]\n",
    "#         dt_y = save_prob_idx(probs,idx)\n",
    "        dt_y = h_x.tolist()\n",
    "        dt_y.insert(0,name)\n",
    "        val_res.append(dt_y)\n",
    "\n",
    "    return val_res\n",
    "\n",
    "\n",
    "\n",
    "val = validation(backbone_network)\n",
    "\n",
    "print('total {} samples'.format(len(val)))\n",
    "\n",
    "# Write into a csv file\n",
    "\n",
    "with open('val_results_{}.csv'.format(backbone_network),'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in val:\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Read the preditctions\n",
    "with open('val_results_{}.csv'.format(backbone_network),\"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    dts = []\n",
    "    for line in reader:\n",
    "        dts.append(line)\n",
    "print('total {} samples'.format(len(dts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the class label\n",
    "file_name = 'categories_places365.txt'\n",
    "if not os.access(file_name, os.W_OK):\n",
    "    synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "    os.system('wget ' + synset_url)\n",
    "classes = list()\n",
    "with open(file_name) as class_file:\n",
    "    for line in class_file:\n",
    "        classes.append(line.strip().split(' ')[0][3:])\n",
    "classes = tuple(classes)\n",
    "\n",
    "# load ground truth\n",
    "with open ('../../places365_data/annotations/places365_val.txt','r') as f:\n",
    "    gts = f.readlines()\n",
    "gts_x = [i.split()[0][10:-4] for i in gts]\n",
    "gts_y = [i.split()[1] for i in gts]\n",
    "gts = {}\n",
    "for i in range(len(gts_x)):\n",
    "    gts[gts_x[i]] = int(gts_y[i])\n",
    "gt = [int(a) for a in list(gts.values())]\n",
    "\n",
    "\n",
    "def top1_prediction (dt):\n",
    "#     print(len(dt))\n",
    "    new_dt = [float(i) for i in dt]\n",
    "    m = max(new_dt)\n",
    "#     print(m)\n",
    "    top1 = [i for i, j in enumerate(new_dt) if j == m]\n",
    "    return top1\n",
    "\n",
    "def top1_accuracy(dts,gts):\n",
    "    total = 0\n",
    "    accurate = 0\n",
    "    for key in dts.keys():\n",
    "        if dts[key] == gts[key]:\n",
    "            accurate +=1\n",
    "        total += 1\n",
    "    return accurate/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_network = 'resnet50'\n",
    "with open('val_results_{}.csv'.format(backbone_network),\"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    dts = []\n",
    "    for line in reader:\n",
    "        dts.append(line)\n",
    "# print('total {} samples'.format(len(dts)))\n",
    "\n",
    "dts_top1 = {}\n",
    "for dt in dts:\n",
    "    dts_top1[dt[0]] = top1_prediction(dt[1:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of resnet50 is 0.5508767123287671\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "top1 = top1_accuracy(dts_top1,gts)\n",
    "print('Top-1 accuracy of {} is {}'.format(backbone_network,float(top1)))\n",
    "\n",
    "\n",
    "# Top-1 accuracy of resnet50 is 0.5508767123287671\n",
    "# Top-1 accuracy of alexnet is 0.4766849315068493\n",
    "# Top-1 accuracy of resnet18 is 0.5385753424657534"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate at higher levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0, 0, 1], 1: [1, 0, 0], 2: [0, 1, 1], 3: [0, 1, 0], 4: [1, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "# level 1\n",
    "\n",
    "import csv\n",
    "level1 = {}\n",
    "with open('../places365_level1.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        level1[int(row[0])]=[int(row[1]),int(row[2]),int(row[3])]    \n",
    "        \n",
    "temp = []\n",
    "for label in level1.keys():\n",
    "    if level1[label] not in temp:\n",
    "        temp.append(level1[label])\n",
    "lv1_classes = {}\n",
    "for i in range(len(temp)):\n",
    "    lv1_classes[i] = temp[i]\n",
    "print(lv1_classes)\n",
    "\n",
    "lv1 = {}\n",
    "for key in level1.keys():\n",
    "    lv1[key] = temp.index(level1[key])\n",
    "# lv1 mapping original class_id to level1_id  \n",
    "\n",
    "def convert_dts2level1 (dt):\n",
    "#     print(len(dt))\n",
    "    dt_new={}\n",
    "    for key in lv1_classes.keys():\n",
    "        dt_new[key] = 0\n",
    "    for i in range(len(dt)):\n",
    "        dt_new[lv1[i]] = float(dt[i]) + float(dt_new[lv1[i]])\n",
    "    flag = 0\n",
    "    temp = 0 \n",
    "    for key in dt_new.keys():\n",
    "        if dt_new[key] > temp:\n",
    "            flag = key\n",
    "            temp  = dt_new[key]\n",
    "        \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping gts to level1\n",
    "\n",
    "\n",
    "# load the class label\n",
    "file_name = 'categories_places365.txt'\n",
    "if not os.access(file_name, os.W_OK):\n",
    "    synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "    os.system('wget ' + synset_url)\n",
    "classes = list()\n",
    "with open(file_name) as class_file:\n",
    "    for line in class_file:\n",
    "        classes.append(line.strip().split(' ')[0][3:])\n",
    "classes = tuple(classes)\n",
    "\n",
    "# load ground truth\n",
    "with open ('../../places365_data/annotations/places365_val.txt','r') as f:\n",
    "    gts = f.readlines()\n",
    "gts_x = [i.split()[0][10:-4] for i in gts]\n",
    "gts_y = [i.split()[1] for i in gts]\n",
    "gts = {}\n",
    "for i in range(len(gts_x)):\n",
    "    gts[gts_x[i]] = int(gts_y[i])\n",
    "\n",
    "gts_lv1 = {}\n",
    "for key in gts.keys():\n",
    "    value = gts[key]\n",
    "    gts_lv1[key] = lv1[value]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of alexnet is 0.8622739726027397\n"
     ]
    }
   ],
   "source": [
    "# mapping dts to level1:\n",
    "\n",
    "\n",
    "backbone_network = 'alexnet'\n",
    "with open('val_results_{}.csv'.format(backbone_network),\"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    dts = []\n",
    "    for line in reader:\n",
    "        dts.append(line)\n",
    "\n",
    "dts_lv1 = {}\n",
    "for dt in dts:\n",
    "    dts_lv1[dt[0]] = convert_dts2level1(dt[1:])\n",
    "    \n",
    "    \n",
    "top1 = top1_accuracy(dts_lv1,gts_lv1)\n",
    "print('Top-1 accuracy of {} is {}'.format(backbone_network,float(top1)))\n",
    "\n",
    "# Top-1 accuracy of resnet50 is 0.8876986301369864\n",
    "# Top-1 accuracy of resnet18 is 0.884027397260274\n",
    "# Top-1 accuracy of alexnet is 0.8622739726027397\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0'], 1: ['0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 2: ['0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 3: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1'], 4: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0'], 5: ['0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 6: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0'], 7: ['0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 8: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0'], 9: ['0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 10: ['1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 11: ['0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0'], 12: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1'], 13: ['0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0'], 14: ['1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 15: ['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0'], 16: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0'], 17: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1'], 18: ['0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 19: ['1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 20: ['0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0', '0'], 21: ['0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '0'], 22: ['0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 23: ['0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0'], 24: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0'], 25: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1'], 26: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1'], 27: ['0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0'], 28: ['1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 29: ['0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 30: ['1', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 31: ['0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0'], 32: ['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '0', '1', '0', '0', '0'], 33: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0'], 34: ['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '0'], 35: ['0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0'], 36: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0'], 37: ['0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 38: ['0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0'], 39: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1'], 40: ['0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0'], 41: ['1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 42: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0'], 43: ['1', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1'], 44: ['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0'], 45: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0'], 46: ['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0'], 47: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1']}\n"
     ]
    }
   ],
   "source": [
    "# level 1\n",
    "\n",
    "import csv\n",
    "level2 = {}\n",
    "with open('../places365_level2.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        level2[int(row[0])]=[row[a] for a in range(1,len(row))]\n",
    "        \n",
    "temp = []\n",
    "for label in level2.keys():\n",
    "    if level2[label] not in temp:\n",
    "        temp.append(level2[label])\n",
    "lv2_classes = {}\n",
    "for i in range(len(temp)):\n",
    "    lv2_classes[i] = temp[i]\n",
    "print(lv2_classes)\n",
    "\n",
    "lv2 = {}\n",
    "for key in level2.keys():\n",
    "    lv2[key] = temp.index(level2[key])\n",
    "# lv1 mapping original class_id to level1_id  \n",
    "\n",
    "def convert_dts2level2 (dt):\n",
    "#     print(len(dt))\n",
    "    dt_new={}\n",
    "    for key in lv2_classes.keys():\n",
    "        dt_new[key] = 0\n",
    "    for i in range(len(dt)):\n",
    "        dt_new[lv2[i]] = float(dt[i]) + float(dt_new[lv2[i]])\n",
    "    flag = 0\n",
    "    temp = 0 \n",
    "    for key in dt_new.keys():\n",
    "        if dt_new[key] > temp:\n",
    "            flag = key\n",
    "            temp  = dt_new[key]\n",
    "        \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping gts to level2\n",
    "\n",
    "\n",
    "# load the class label\n",
    "file_name = 'categories_places365.txt'\n",
    "if not os.access(file_name, os.W_OK):\n",
    "    synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "    os.system('wget ' + synset_url)\n",
    "classes = list()\n",
    "with open(file_name) as class_file:\n",
    "    for line in class_file:\n",
    "        classes.append(line.strip().split(' ')[0][3:])\n",
    "classes = tuple(classes)\n",
    "\n",
    "# load ground truth\n",
    "with open ('../../places365_data/annotations/places365_val.txt','r') as f:\n",
    "    gts = f.readlines()\n",
    "gts_x = [i.split()[0][10:-4] for i in gts]\n",
    "gts_y = [i.split()[1] for i in gts]\n",
    "gts = {}\n",
    "for i in range(len(gts_x)):\n",
    "    gts[gts_x[i]] = int(gts_y[i])\n",
    "\n",
    "gts_lv2 = {}\n",
    "for key in gts.keys():\n",
    "    value = gts[key]\n",
    "    gts_lv2[key] = lv2[value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy of resnet18 is 0.7152876712328767\n"
     ]
    }
   ],
   "source": [
    "# mapping dts to level1:\n",
    "\n",
    "\n",
    "backbone_network = 'resnet18'\n",
    "with open('val_results_{}.csv'.format(backbone_network),\"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    dts = []\n",
    "    for line in reader:\n",
    "        dts.append(line)\n",
    "\n",
    "dts_lv2 = {}\n",
    "for dt in dts:\n",
    "    dts_lv2[dt[0]] = convert_dts2level2(dt[1:])\n",
    "    \n",
    "    \n",
    "top1 = top1_accuracy(dts_lv2,gts_lv2)\n",
    "print('Top-1 accuracy of {} is {}'.format(backbone_network,float(top1)))\n",
    "\n",
    "\n",
    "# Top-1 accuracy of resnet50 is 0.7248767123287672\n",
    "# Top-1 accuracy of resnet18 is 0.7152876712328767\n",
    "# Top-1 accuracy of alexnet is 0.6586301369863014"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo",
   "language": "python",
   "name": "neo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
